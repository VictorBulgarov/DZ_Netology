{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d65c1a7b",
   "metadata": {},
   "source": [
    "## Задание\n",
    "\n",
    "Постройте модель на основе полносвязных слоёв для классификации Fashion MNIST из библиотеки torchvision (datasets).\n",
    "Получите качество на тестовой выборке не ниже 88%\n",
    "\n",
    "Инструкция по выполнению задания\n",
    "\n",
    "Скачайте тренировочную и тестовою часть датасета\n",
    "Постройте модель, выбрав стартовую архитектуру\n",
    "Обучите модель и сверьте качество на тестовой части с заданным порогом\n",
    "Изменяйте архитектуру модели пока качество на тестовой части не будет выше порога. Вариации архитектуры можно реализовать через изменение количества слоёв, количества нейронов в слоях и использование регуляризации. Можно использовать различные оптимизаторы.\n",
    "Формат сдачи работы\n",
    "\n",
    "Прикрепите ссылку на готовое решение в личном кабинете. Работу можно отправлять в виде ссылки на python-ноутбук из GitHub, Google Colaboratory или аналогичных платформ. Не забудьте открыть доступ на просмотр и комментирование.\n",
    "\n",
    "Критерии оценки\n",
    "\n",
    "По итогу выполнения задания вы получите зачёт.\n",
    "\n",
    "Задание считается выполненным, если:\n",
    "\n",
    "модель обучается\n",
    "модель показала качество на тесте более 88%\n",
    "Задание будет отправлено на доработку, если:\n",
    "\n",
    "модель вообще не обучилась\n",
    "качество на тесте ниже порога"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b778dfab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50611f52476a42fa83283d4e5b5534b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26421880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c1e529af4c46a697b5773395a25656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29515 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65a9c1dab254f6282a423a4d0dac8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4422102 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a285cc39a3414ea8b6d9f4c82693cab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Epoch: 1 \tTraining Loss: 0.007843 \tTraining Accuracy: 81.95% \tTest Loss: 0.007165 \tTest Accuracy: 83.31%\n",
      "Epoch: 2 \tTraining Loss: 0.005981 \tTraining Accuracy: 86.11% \tTest Loss: 0.006561 \tTest Accuracy: 84.54%\n",
      "Epoch: 3 \tTraining Loss: 0.005430 \tTraining Accuracy: 87.28% \tTest Loss: 0.005749 \tTest Accuracy: 86.54%\n",
      "Epoch: 4 \tTraining Loss: 0.005033 \tTraining Accuracy: 88.11% \tTest Loss: 0.005657 \tTest Accuracy: 86.96%\n",
      "Epoch: 5 \tTraining Loss: 0.004714 \tTraining Accuracy: 88.73% \tTest Loss: 0.005745 \tTest Accuracy: 86.72%\n",
      "Epoch: 6 \tTraining Loss: 0.004491 \tTraining Accuracy: 89.46% \tTest Loss: 0.005692 \tTest Accuracy: 87.02%\n",
      "Epoch: 7 \tTraining Loss: 0.004256 \tTraining Accuracy: 89.87% \tTest Loss: 0.005580 \tTest Accuracy: 87.65%\n",
      "Epoch: 8 \tTraining Loss: 0.004097 \tTraining Accuracy: 90.17% \tTest Loss: 0.005497 \tTest Accuracy: 87.80%\n",
      "Epoch: 9 \tTraining Loss: 0.003923 \tTraining Accuracy: 90.71% \tTest Loss: 0.005749 \tTest Accuracy: 87.27%\n",
      "Epoch: 10 \tTraining Loss: 0.003792 \tTraining Accuracy: 90.86% \tTest Loss: 0.005364 \tTest Accuracy: 87.87%\n",
      "Epoch: 1 \tTraining Loss: 0.010960 \tTraining Accuracy: 74.67% \tTest Loss: 0.007575 \tTest Accuracy: 82.24%\n",
      "Epoch: 2 \tTraining Loss: 0.008272 \tTraining Accuracy: 81.66% \tTest Loss: 0.006878 \tTest Accuracy: 83.80%\n",
      "Epoch: 3 \tTraining Loss: 0.007666 \tTraining Accuracy: 82.93% \tTest Loss: 0.006696 \tTest Accuracy: 84.41%\n",
      "Epoch: 4 \tTraining Loss: 0.007420 \tTraining Accuracy: 83.44% \tTest Loss: 0.006379 \tTest Accuracy: 85.17%\n",
      "Epoch: 5 \tTraining Loss: 0.007081 \tTraining Accuracy: 83.98% \tTest Loss: 0.006140 \tTest Accuracy: 85.79%\n",
      "Epoch: 6 \tTraining Loss: 0.006926 \tTraining Accuracy: 84.32% \tTest Loss: 0.006524 \tTest Accuracy: 84.15%\n",
      "Epoch: 7 \tTraining Loss: 0.006762 \tTraining Accuracy: 84.94% \tTest Loss: 0.006079 \tTest Accuracy: 85.63%\n",
      "Epoch: 8 \tTraining Loss: 0.006598 \tTraining Accuracy: 85.36% \tTest Loss: 0.005931 \tTest Accuracy: 86.03%\n",
      "Epoch: 9 \tTraining Loss: 0.006562 \tTraining Accuracy: 85.32% \tTest Loss: 0.005792 \tTest Accuracy: 86.86%\n",
      "Epoch: 10 \tTraining Loss: 0.006434 \tTraining Accuracy: 85.79% \tTest Loss: 0.005740 \tTest Accuracy: 86.88%\n",
      "Epoch: 11 \tTraining Loss: 0.006334 \tTraining Accuracy: 85.76% \tTest Loss: 0.005733 \tTest Accuracy: 86.66%\n",
      "Epoch: 12 \tTraining Loss: 0.006267 \tTraining Accuracy: 86.15% \tTest Loss: 0.005703 \tTest Accuracy: 86.72%\n",
      "Epoch: 13 \tTraining Loss: 0.006200 \tTraining Accuracy: 86.11% \tTest Loss: 0.005566 \tTest Accuracy: 87.31%\n",
      "Epoch: 14 \tTraining Loss: 0.006151 \tTraining Accuracy: 86.30% \tTest Loss: 0.005676 \tTest Accuracy: 87.19%\n",
      "Epoch: 15 \tTraining Loss: 0.006107 \tTraining Accuracy: 86.54% \tTest Loss: 0.005728 \tTest Accuracy: 86.68%\n",
      "Epoch: 16 \tTraining Loss: 0.006060 \tTraining Accuracy: 86.41% \tTest Loss: 0.005533 \tTest Accuracy: 87.33%\n",
      "Epoch: 17 \tTraining Loss: 0.005987 \tTraining Accuracy: 86.77% \tTest Loss: 0.005571 \tTest Accuracy: 87.21%\n",
      "Epoch: 18 \tTraining Loss: 0.005926 \tTraining Accuracy: 86.75% \tTest Loss: 0.005690 \tTest Accuracy: 86.80%\n",
      "Epoch: 19 \tTraining Loss: 0.005890 \tTraining Accuracy: 86.94% \tTest Loss: 0.005574 \tTest Accuracy: 87.19%\n",
      "Epoch: 20 \tTraining Loss: 0.005905 \tTraining Accuracy: 86.83% \tTest Loss: 0.005350 \tTest Accuracy: 87.98%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Загрузка данных\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Определение модели\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Обучение модели\n",
    "def train(model, optimizer, criterion, train_loader):\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        train_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        train_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_acc = 100. * train_correct / len(train_loader.dataset)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "# Оценка модели на тестовом наборе данных\n",
    "def test(model, criterion, test_loader):\n",
    "    test_loss = 0\n",
    "    test_correct = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            test_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = 100. * test_correct / len(test_loader.dataset)\n",
    "    return test_loss, test_acc\n",
    "\n",
    "# Обучение модели и оценка ее точности на тестовом наборе данных\n",
    "model = SimpleNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(10):\n",
    "    train_loss, train_acc = train(model, optimizer, criterion, train_loader)\n",
    "    test_loss, test_acc = test(model, criterion, test_loader)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tTraining Accuracy: {:.2f}% \\tTest Loss: {:.6f} \\tTest Accuracy: {:.2f}%'.format(\n",
    "        epoch+1, train_loss, train_acc, test_loss, test_acc))\n",
    "\n",
    "    if test_acc > 88:\n",
    "        break\n",
    "\n",
    "# Добавление слоя и dropout\n",
    "class ComplexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ComplexNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Обучение модели и оценка ее точности на тестовом наборе данных\n",
    "model = ComplexNet()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(20):\n",
    "    train_loss, train_acc = train(model, optimizer, criterion, train_loader)\n",
    "    test_loss, test_acc = test(model, criterion, test_loader)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tTraining Accuracy: {:.2f}% \\tTest Loss: {:.6f} \\tTest Accuracy: {:.2f}%'.format(\n",
    "        epoch+1, train_loss, train_acc, test_loss, test_acc))\n",
    "\n",
    "    if test_acc > 88:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b18112a",
   "metadata": {},
   "source": [
    "Заданное качество на тестовой выборке не ниже 88% - получено."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494a8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
